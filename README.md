# mlxllama
working towards a fast reimplementation of llama-2 in mlx
